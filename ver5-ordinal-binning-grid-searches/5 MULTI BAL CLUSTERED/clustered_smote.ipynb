{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand a labeled dataset to SMOTE\n",
    "\n",
    "magnify the number of minority/exceptional cases within the sequence dataset, ideally targets the binary binned dataset.\n",
    "\n",
    "[reference 1](<ver5-ordinal-binning-grid-searches/step 2-0, ranged clustering, with time.ipynb>)\n",
    "\n",
    "different oversampling tools: Naive random oversampling, SMOTE, ADASYN, SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE,SMOTENC, KMeansSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.ensemble import BalancedBaggingClassifier,BalancedRandomForestClassifier,RUSBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier, RandomForestClassifier, \\\n",
    "ExtraTreesClassifier, RandomTreesEmbedding, BaggingClassifier\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import shap\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import altair as alt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import  VotingClassifier \n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_pipeline = pd.read_csv(\"binary_binned_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'precursor_buy_cap_pct_change',\n",
       "       'precursor_ask_cap_pct_change', 'precursor_bid_vol_pct_change',\n",
       "       'precursor_ask_vol_pct_change', 'sum_change', 'length',\n",
       "       'surge_targets_met_pct', 'time', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_pipeline.columns #do this to identify the index of the categorical feature, for below setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepable = ['precursor_buy_cap_pct_change', \n",
    "            'precursor_ask_cap_pct_change',\n",
    "            'precursor_bid_vol_pct_change', \n",
    "            'precursor_ask_vol_pct_change',\n",
    "            'sum_change','length','time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = m2_pipeline['label'] #per https://stackoverflow.com/a/73095562/12001832\n",
    "X = m2_pipeline[keepable]\n",
    "# Performing the test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#normalize all numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precursor_buy_cap_pct_change</th>\n",
       "      <th>precursor_ask_cap_pct_change</th>\n",
       "      <th>precursor_bid_vol_pct_change</th>\n",
       "      <th>precursor_ask_vol_pct_change</th>\n",
       "      <th>sum_change</th>\n",
       "      <th>length</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>6</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003129</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.004203</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>1</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>3</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003818</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>2</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>-0.013463</td>\n",
       "      <td>7</td>\n",
       "      <td>1.660223e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>-0.127842</td>\n",
       "      <td>0.226017</td>\n",
       "      <td>0.815279</td>\n",
       "      <td>0.144134</td>\n",
       "      <td>-0.045466</td>\n",
       "      <td>5</td>\n",
       "      <td>1.693073e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>-0.003810</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>5</td>\n",
       "      <td>1.693073e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>6</td>\n",
       "      <td>1.693073e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>11</td>\n",
       "      <td>1.693074e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>-0.015598</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>-0.003830</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>2</td>\n",
       "      <td>1.693077e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5826 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      precursor_buy_cap_pct_change  precursor_ask_cap_pct_change  \\\n",
       "0                        -0.000798                      0.000046   \n",
       "1                        -0.003129                     -0.000032   \n",
       "2                         0.000440                     -0.000007   \n",
       "3                        -0.003818                      0.000013   \n",
       "4                         0.009044                      0.000025   \n",
       "...                            ...                           ...   \n",
       "5821                     -0.127842                      0.226017   \n",
       "5822                     -0.003810                      0.000425   \n",
       "5823                      0.003263                      0.000408   \n",
       "5824                      0.004464                      0.000645   \n",
       "5825                     -0.015598                      0.000442   \n",
       "\n",
       "      precursor_bid_vol_pct_change  precursor_ask_vol_pct_change  sum_change  \\\n",
       "0                        -0.000173                      0.006228   -0.004876   \n",
       "1                        -0.001081                     -0.004203   -0.000134   \n",
       "2                         0.000294                     -0.000717   -0.004013   \n",
       "3                        -0.001505                      0.001104   -0.000300   \n",
       "4                         0.004399                      0.007863   -0.013463   \n",
       "...                            ...                           ...         ...   \n",
       "5821                      0.815279                      0.144134   -0.045466   \n",
       "5822                     -0.000934                      0.002042   -0.000498   \n",
       "5823                      0.000792                      0.001959   -0.000598   \n",
       "5824                      0.001073                      0.003142   -0.000996   \n",
       "5825                     -0.003830                      0.002162   -0.000498   \n",
       "\n",
       "      length          time  \n",
       "0          6  1.660222e+12  \n",
       "1          1  1.660222e+12  \n",
       "2          3  1.660222e+12  \n",
       "3          2  1.660222e+12  \n",
       "4          7  1.660223e+12  \n",
       "...      ...           ...  \n",
       "5821       5  1.693073e+12  \n",
       "5822       5  1.693073e+12  \n",
       "5823       6  1.693073e+12  \n",
       "5824      11  1.693074e+12  \n",
       "5825       2  1.693077e+12  \n",
       "\n",
       "[5826 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up toolsets as functions to build separate datasets, bin_Naive, bin_SMOTE, bin_ADASYN\n",
    "\n",
    "def build_naive():  #https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling\n",
    "    ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    print(\"ROS\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_smote(): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#smote\n",
    "    X_resampled, y_resampled = SMOTE(random_state=42 ).fit_resample(X, y)\n",
    "    print(\"SMOTE\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_adasyn(): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#adasyn\n",
    "    X_resampled, y_resampled = ADASYN(random_state=42,sampling_strategy='minority').fit_resample(X, y)\n",
    "    print(\"ADASYN\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_borderline(): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#borderlinesmote\n",
    "    X_resampled, y_resampled = BorderlineSMOTE(random_state=42,sampling_strategy='minority').fit_resample(X, y)\n",
    "    print(\"BORDERLINE\",sorted(Counter(y_resampled).items())) \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_smotenc(): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#smotenc\n",
    "    smote_nc = SMOTENC( random_state=42,sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "    print(\"SMOTENC\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_svmsmote():\n",
    "    sm = SVMSMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    print(\"SVMSMOTE\",'Resampled dataset shape %s' % Counter(y_res))\n",
    "    return X_res, y_res\n",
    "\n",
    "def build_kmsmote(): #https://imbalanced-learn.org/stable/combine.html#combination-of-over-and-under-sampling\n",
    "    m = KMeansSMOTE( random_state=42,sampling_strategy='minority')\n",
    "    X_res, y_res = m.fit_resample(X, y)\n",
    "    # Find the number of new samples in the middle blob\n",
    "    n_res_in_middle = ((X_res[:, 0] > -5) & (X_res[:, 0] < 5)).sum()\n",
    "    print(\"KMSMOTE\",\"Samples in the middle blob: %s\" % n_res_in_middle)\n",
    "    return X_res, y_res\n",
    "\n",
    "def build_smoteenn():\n",
    "    smote_enn = SMOTEENN(random_state=42,sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "    print(\"SMOTEENN\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_smotetomek():\n",
    "    smote_tomek = SMOTETomek(random_state=42,sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "    print(\"SMOTETOMEK\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take optimal classifier parameters and technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestClassifier(oversampler, dataset):   #'kmsmote', build_svmsmote(source)\n",
    "    classifiers = [  # Define the classifiers and their respective hyperparameters\n",
    "        LogisticRegression(),\n",
    "        BernoulliNB(),\n",
    "        KNeighborsClassifier(),\n",
    "    ]\n",
    "    params = {\n",
    "        'LogisticRegression':{'C': [0.1, 1, 10], 'penalty':['l1','l2','elasticnet','None'], 'multi_class':['ovr','auto'],\\\n",
    "                              'random_state':[42]},\n",
    "        'BernoulliNB':{'fit_prior':[True, False]},\n",
    "        'KNeighborsClassifier':{'n_neighbors':[3,4,5,6,7,8], 'algorithm':['auto'], 'n_jobs':[1,2,3,4]}\n",
    "    }\n",
    "    comparative = []\n",
    "    # Perform the grid search\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        if name in params:\n",
    "            grid_search = GridSearchCV(clf, params[name], cv=5)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "            accuracy = grid_search.score(X_test, y_test)\n",
    "            \n",
    "            dict = {\"classifier\":name, \"best_params\":grid_search.best_params_, \"accuracy\":accuracy, \"oversampler\":oversampler}\n",
    "            comparative.append(dict)\n",
    "    return(comparative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROS [(0, 5716), (1, 5716)]\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n"
     ]
    }
   ],
   "source": [
    "samplers = [build_naive(),build_smote(),build_adasyn(), build_borderline(), build_svmsmote(), build_smoteenn(),build_smotetomek()]\n",
    "samplers_string = [\"build_naive\",\"build_smote\",\"build_adasyn\", \"build_borderline\", \"build_svmsmote\", \"build_smoteenn\",\"build_smotetomek\"]\n",
    "samplers_tup = zip(samplers_string,samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_clusters = 2\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "def silhouette_scorer(estimator, X, y=None):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_naive sihlouette score is 0.6843542974684024 and profit score is 0.690628255221736.\n",
      "build_smote sihlouette score is 0.7934490264209996 and profit score is 0.7154194361373594.\n",
      "build_adasyn sihlouette score is 0.7303924816391958 and profit score is 0.6832464734271906.\n",
      "build_borderline sihlouette score is 0.5941545457892622 and profit score is 0.6739884023965783.\n",
      "build_svmsmote sihlouette score is 0.6278030339457474 and profit score is 0.6982836479341944.\n",
      "build_smoteenn sihlouette score is 0.6308211271722189 and profit score is 0.6726724663335935.\n",
      "build_smotetomek sihlouette score is 0.7815931034255095 and profit score is 0.6582383332931642.\n"
     ]
    }
   ],
   "source": [
    "for pair in samplers_tup:\n",
    "    sampler_string, sampler = pair\n",
    "    X_sampled, y_sampled = sampler\n",
    "    #normalize all numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_sampled)\n",
    "    clf = KMeans(n_clusters =2, init='k-means++', random_state = 42)\n",
    "    labels = clf.fit_predict(X_train_scaled)\n",
    "\n",
    "    df = pd.DataFrame({'y_sampled': y_sampled, 'Cluster_Label': labels})\n",
    "    \n",
    "    # Calculate the ratio of the larger count of labels (0 or 1) to the total count in each cluster\n",
    "    cluster_ratios = df.groupby('Cluster_Label')['y_sampled'].value_counts().unstack().fillna(0)\n",
    "    cluster_max_ratio = cluster_ratios.max(axis=1)\n",
    "    cluster_total_count = cluster_ratios.sum(axis=1)\n",
    "    cluster_profit_scores = cluster_max_ratio / cluster_total_count\n",
    "    \n",
    "    # Calculate the average profit score across clusters\n",
    "    average_profit_score = np.mean(cluster_profit_scores)\n",
    "    sihlouette_score = silhouette_score(X_train_scaled, labels)\n",
    "    print(f\"{str(sampler_string)} sihlouette score is {sihlouette_score} and profit score is {average_profit_score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = [build_naive,build_smote,build_adasyn,build_borderline,build_svmsmote,build_smoteenn,build_smotetomek]\n",
    "samplers_string = [\"build_naive\",\"build_smote\",\"build_adasyn\", \"build_borderline\", \"build_svmsmote\", \"build_smoteenn\",\"build_smotetomek\"]\n",
    "sampler_dict = {k: v for k, v in zip(samplers_string, samplers )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'build_naive': <function __main__.build_naive()>,\n",
       " 'build_smote': <function __main__.build_smote()>,\n",
       " 'build_adasyn': <function __main__.build_adasyn()>,\n",
       " 'build_borderline': <function __main__.build_borderline()>,\n",
       " 'build_svmsmote': <function __main__.build_svmsmote()>,\n",
       " 'build_smoteenn': <function __main__.build_smoteenn()>,\n",
       " 'build_smotetomek': <function __main__.build_smotetomek()>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_naive sihlouette score is 0.5589780011241178 and profit score is 0.7272286121639467.\n",
      "build_smote sihlouette score is 0.295312906627782 and profit score is 0.7206832500545338.\n",
      "build_adasyn sihlouette score is 0.289928919274235 and profit score is 0.7219462502320038.\n",
      "build_borderline sihlouette score is 0.29103835498727487 and profit score is 0.71706226287071.\n",
      "build_svmsmote sihlouette score is 0.2922209036457123 and profit score is 0.7312030720456777.\n",
      "build_smoteenn sihlouette score is 0.296901224155592 and profit score is 0.7325067190264691.\n",
      "build_smotetomek sihlouette score is 0.3008564059891155 and profit score is 0.7264925722739589.\n"
     ]
    }
   ],
   "source": [
    "# n_clusters = 10\n",
    "for pair in samplers_tup:\n",
    "    sampler_string, sampler = pair\n",
    "    X_sampled, y_sampled = sampler\n",
    "    #normalize all numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_sampled)\n",
    "    clf = KMeans(n_clusters =4, init='k-means++', random_state = 42)\n",
    "    labels = clf.fit_predict(X_train_scaled)\n",
    "\n",
    "    df = pd.DataFrame({'y_sampled': y_sampled, 'Cluster_Label': labels})\n",
    "    \n",
    "    # Calculate the ratio of the larger count of labels (0 or 1) to the total count in each cluster\n",
    "    cluster_ratios = df.groupby('Cluster_Label')['y_sampled'].value_counts().unstack().fillna(0)\n",
    "    cluster_max_ratio = cluster_ratios.max(axis=1)\n",
    "    cluster_total_count = cluster_ratios.sum(axis=1)\n",
    "    cluster_profit_scores = cluster_max_ratio / cluster_total_count\n",
    "    \n",
    "    # Calculate the average profit score across clusters\n",
    "    average_profit_score = np.mean(cluster_profit_scores)\n",
    "    sihlouette_score = silhouette_score(X_train_scaled, labels)\n",
    "    print(f\"{str(sampler_string)} sihlouette score is {sihlouette_score} and profit score is {average_profit_score}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_clusters is equal to 2.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.6843542974684024 and profit score is 0.690628255221736.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.7934490264209996 and profit score is 0.7154194361373594.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.7303924816391958 and profit score is 0.6832464734271906.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.5941545457892622 and profit score is 0.6739884023965783.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.6278030339457474 and profit score is 0.6982836479341944.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.6308211271722189 and profit score is 0.6726724663335935.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.7815931034255095 and profit score is 0.6582383332931642.\n",
      "N_clusters is equal to 4.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.5589780011241178 and profit score is 0.7272286121639467.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.295312906627782 and profit score is 0.7206832500545338.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.289928919274235 and profit score is 0.7219462502320038.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.29103835498727487 and profit score is 0.71706226287071.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.2922209036457123 and profit score is 0.7312030720456777.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.296901224155592 and profit score is 0.7325067190264691.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.3008564059891155 and profit score is 0.7264925722739589.\n",
      "N_clusters is equal to 6.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.3194877635174486 and profit score is 0.7547754169809999.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.2876880298912991 and profit score is 0.7293691212883674.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.2822529525868858 and profit score is 0.72140793275213.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.3428357601468926 and profit score is 0.755061379958609.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.3224435152460604 and profit score is 0.7466315145034131.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.3161942050581798 and profit score is 0.7453770667239739.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.30634903676221487 and profit score is 0.7550515043384031.\n",
      "N_clusters is equal to 8.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.34777224578708904 and profit score is 0.7595627222988623.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.31188920930047775 and profit score is 0.7549867042047879.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.31013612882389635 and profit score is 0.7533336099845154.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.3375891363081979 and profit score is 0.7537707354479488.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.33911868932801165 and profit score is 0.7482821180704228.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.32290066493830044 and profit score is 0.7340505895450039.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.3210732562147963 and profit score is 0.7612408694486777.\n",
      "N_clusters is equal to 10.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.3136051328127353 and profit score is 0.7593645672362724.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.25504176847866333 and profit score is 0.7466175896092193.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.2548928644093638 and profit score is 0.7518683098607664.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.26736736035729153 and profit score is 0.7366625033482663.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.30378902860805296 and profit score is 0.7287963996840167.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.2647088379581408 and profit score is 0.7407269003587397.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.25900066715513403 and profit score is 0.7306449615070355.\n",
      "N_clusters is equal to 12.\n",
      "ROS [(0, 5716), (1, 5716)]\n",
      "build_naive sihlouette score is 0.30787228773450753 and profit score is 0.7260828499186055.\n",
      "SMOTE [(0, 5716), (1, 5716)]\n",
      "build_smote sihlouette score is 0.26802968308795255 and profit score is 0.7233006855653424.\n",
      "ADASYN [(0, 5716), (1, 5701)]\n",
      "build_adasyn sihlouette score is 0.2638956130758023 and profit score is 0.7625061732774644.\n",
      "BORDERLINE [(0, 5716), (1, 5716)]\n",
      "build_borderline sihlouette score is 0.27875093210301133 and profit score is 0.7437917544454672.\n",
      "SVMSMOTE Resampled dataset shape Counter({0: 5716, 1: 3193})\n",
      "build_svmsmote sihlouette score is 0.27636156031151354 and profit score is 0.7214925091058673.\n",
      "SMOTEENN [(0, 2972), (1, 2334)]\n",
      "build_smoteenn sihlouette score is 0.2735149011684939 and profit score is 0.7579922576768178.\n",
      "SMOTETOMEK [(0, 4377), (1, 4377)]\n",
      "build_smotetomek sihlouette score is 0.2659610375620554 and profit score is 0.7486009758667412.\n"
     ]
    }
   ],
   "source": [
    "samplers = [build_naive,build_smote,build_adasyn,build_borderline,build_svmsmote,build_smoteenn,build_smotetomek]\n",
    "samplers_string = [\"build_naive\",\"build_smote\",\"build_adasyn\", \"build_borderline\", \"build_svmsmote\", \"build_smoteenn\",\"build_smotetomek\"]\n",
    "sampler_dict = {k: v for k, v in zip(samplers_string, samplers )}\n",
    "n_clusters = [2,4,6,8,10,12]\n",
    "for clus in n_clusters:\n",
    "    print(f\"N_clusters is equal to {clus}.\")\n",
    "    for key, value in sampler_dict.items():\n",
    "        X_sampled, y_sampled = value()\n",
    "        #normalize all numeric columns\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_sampled)\n",
    "        clf = KMeans(n_clusters =clus, init='k-means++', random_state = 42)\n",
    "        labels = clf.fit_predict(X_train_scaled)\n",
    "\n",
    "        df = pd.DataFrame({'y_sampled': y_sampled, 'Cluster_Label': labels})\n",
    "\n",
    "        # Calculate the ratio of the larger count of labels (0 or 1) to the total count in each cluster\n",
    "        cluster_ratios = df.groupby('Cluster_Label')['y_sampled'].value_counts().unstack().fillna(0)\n",
    "        cluster_max_ratio = cluster_ratios.max(axis=1)\n",
    "        cluster_total_count = cluster_ratios.sum(axis=1)\n",
    "        cluster_profit_scores = cluster_max_ratio / cluster_total_count\n",
    "\n",
    "        # Calculate the average profit score across clusters\n",
    "        average_profit_score = np.mean(cluster_profit_scores)\n",
    "        silhouette_score_1 = silhouette_score(X_train_scaled, labels)\n",
    "        print(f\"{str(key)} sihlouette score is {silhouette_score_1} and profit score is {average_profit_score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE [(0, 5716), (1, 5716)]\n"
     ]
    }
   ],
   "source": [
    "X_sampled, y_sampled = build_smote()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_sampled)\n",
    "clf = KMeans(n_clusters =2, init='k-means++', random_state = 42)\n",
    "labels = clf.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precursor_buy_cap_pct_change</th>\n",
       "      <th>precursor_ask_cap_pct_change</th>\n",
       "      <th>precursor_bid_vol_pct_change</th>\n",
       "      <th>precursor_ask_vol_pct_change</th>\n",
       "      <th>sum_change</th>\n",
       "      <th>length</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>6</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003129</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.004203</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>1</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>3</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003818</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>2</td>\n",
       "      <td>1.660222e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>-0.013463</td>\n",
       "      <td>7</td>\n",
       "      <td>1.660223e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>0.041228</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>-0.008161</td>\n",
       "      <td>2</td>\n",
       "      <td>1.663482e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>0.048216</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>-0.003788</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>4</td>\n",
       "      <td>1.679312e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>-0.021210</td>\n",
       "      <td>0.040257</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>0.114004</td>\n",
       "      <td>-0.034555</td>\n",
       "      <td>5</td>\n",
       "      <td>1.686772e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>0.128101</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.155690</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>1</td>\n",
       "      <td>1.660483e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>-0.017743</td>\n",
       "      <td>1</td>\n",
       "      <td>1.675269e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11432 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       precursor_buy_cap_pct_change  precursor_ask_cap_pct_change  \\\n",
       "0                         -0.000798                      0.000046   \n",
       "1                         -0.003129                     -0.000032   \n",
       "2                          0.000440                     -0.000007   \n",
       "3                         -0.003818                      0.000013   \n",
       "4                          0.009044                      0.000025   \n",
       "...                             ...                           ...   \n",
       "11427                      0.041228                      0.000184   \n",
       "11428                      0.048216                     -0.001025   \n",
       "11429                     -0.021210                      0.040257   \n",
       "11430                      0.128101                      0.000938   \n",
       "11431                      0.037207                      0.003334   \n",
       "\n",
       "       precursor_bid_vol_pct_change  precursor_ask_vol_pct_change  sum_change  \\\n",
       "0                         -0.000173                      0.006228   -0.004876   \n",
       "1                         -0.001081                     -0.004203   -0.000134   \n",
       "2                          0.000294                     -0.000717   -0.004013   \n",
       "3                         -0.001505                      0.001104   -0.000300   \n",
       "4                          0.004399                      0.007863   -0.013463   \n",
       "...                             ...                           ...         ...   \n",
       "11427                      0.014091                      0.008272   -0.008161   \n",
       "11428                      0.007441                     -0.003788   -0.012447   \n",
       "11429                      0.026512                      0.114004   -0.034555   \n",
       "11430                      0.039594                      0.155690   -0.004880   \n",
       "11431                      0.016551                      0.008364   -0.017743   \n",
       "\n",
       "       length          time  \n",
       "0           6  1.660222e+12  \n",
       "1           1  1.660222e+12  \n",
       "2           3  1.660222e+12  \n",
       "3           2  1.660222e+12  \n",
       "4           7  1.660223e+12  \n",
       "...       ...           ...  \n",
       "11427       2  1.663482e+12  \n",
       "11428       4  1.679312e+12  \n",
       "11429       5  1.686772e+12  \n",
       "11430       1  1.660483e+12  \n",
       "11431       1  1.675269e+12  \n",
       "\n",
       "[11432 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_sampled.reset_index(drop=True), pd.Series(labels, name='Cluster_Label')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, y_sampled], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"binary_clustered_resampled_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "for pair in samplers_tup:\n",
    "    sampler_string, sampler = pair\n",
    "    X_sampled, y_sampled = sampler\n",
    "    #normalize all numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_sampled)\n",
    "    clf = KMeans(n_clusters =2, init='k-means++', random_state = 42)\n",
    "    labels = clf.fit_predict(X_train_scaled)\n",
    "    df = pd.concat([y_sampled.reset_index(drop=True), pd.Series(labels, name='Cluster_Label')], axis=1)\n",
    "    cluster_means = df.groupby('Cluster_Label')['label'].mean()\n",
    "    score = cluster_means.std() \n",
    "    sihlouette_score = silhouette_score(X_train_scaled, labels)\n",
    "    print(f\"{sampler_string} sihlouette score is {sihlouette_score} and profit score is {score}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigger the search mechanism, per SMOTE method\n",
    "\n",
    "loop through each oversampled dataset, then run the classifier search on that set, outlining each set, before hand\n",
    "\n",
    "for each set, run the classifier search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROS [(0, 5716), (1, 5716)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8754, 4660]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f100c7e3ef2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_binned_pipeline.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresultSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresultSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetBestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'naive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#many rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresultSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetBestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'smote'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresultSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetBestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adasyn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_adasyn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-faf1a6007085>\u001b[0m in \u001b[0;36mgetBestClassifier\u001b[0;34m(oversampler, dataset)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters for {name}: {grid_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8754, 4660]"
     ]
    }
   ],
   "source": [
    "\n",
    "source = 'binary_binned_pipeline.csv'\n",
    "resultSet = []\n",
    "resultSet.append(getBestClassifier('naive', build_naive()))  #many rows\n",
    "resultSet.append(getBestClassifier('smote', build_smote()))\n",
    "resultSet.append(getBestClassifier('adasyn', build_adasyn()))\n",
    "resultSet.append(getBestClassifier('borderline', build_borderline()))\n",
    "# resultSet.append(getBestClassifier('smotenc', build_smotenc()))\n",
    "resultSet.append(getBestClassifier('svmsmote', build_svmsmote()))\n",
    "# resultSet.append(getBestClassifier('kmsmote', build_kmsmote()))\n",
    "resultSet.append(getBestClassifier('smoteenn', build_smoteenn()))\n",
    "resultSet.append(getBestClassifier('smotetomek', build_smotetomek()))\n",
    "\n",
    "optimals = pd.DataFrame(resultSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-eb83d6c13d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimals' is not defined"
     ]
    }
   ],
   "source": [
    "optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f127abee1db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Apply the lambda function to each row of the data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimals' is not defined"
     ]
    }
   ],
   "source": [
    "print_dict = lambda x: print(x)\n",
    "\n",
    "# Apply the lambda function to each row of the data frame\n",
    "optimals.applymap(print_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pitfalls of oversampling](https://imbalanced-learn.org/stable/common_pitfalls.html#data-leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sampling based ensemble methods\n",
    "\n",
    "score each, can you combine into a voter?\n",
    "\n",
    "[validation curve model selection](https://imbalanced-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#plotting-validation-curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8754, 4660]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-aabc464963fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 random_state=42)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/utils/fixes.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     )\n\u001b[1;32m     84\u001b[0m                 ):\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# overwrite the base class method by disallowing `sample_weight`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         )\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8754, 4660]"
     ]
    }
   ],
   "source": [
    "# balanced bagger\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=LogisticRegression(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc.fit(X_train_scaled, y_train)\n",
    "y_pred = bbc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5864746945898779"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced tree estimator\n",
    "brf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100, random_state=42, sampling_strategy=\"all\", replacement=True\n",
    ")\n",
    "brf.fit(X_train_scaled, y_train)\n",
    "y_pred = brf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',\n",
    "                              random_state=42)\n",
    "rusboost.fit(X_train_scaled, y_train)\n",
    "y_pred = rusboost.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.05) [BalancedBaggingClassifier]\n",
      "Accuracy: 0.77 (+/- 0.03) [BalancedRandomForestClassifier]\n",
      "Accuracy: 0.88 (+/- 0.06) [RUSBoostClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "`base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.03) [Voting]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = m2_pipeline[keepable].values  #.drop(columns=['label']).values #per https://stackoverflow.com/a/73095562/12001832\n",
    "y = m2_pipeline['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#normalize all numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "vc = VotingClassifier(estimators=[('bbc',bbc),('brf',brf),('rusboost',rusboost)], voting='soft')#  , weights=weights) \n",
    "# #fit all, voting classifier scoring\n",
    "for clf, label in zip([bbc,brf,rusboost,vc], ['BalancedBaggingClassifier','BalancedRandomForestClassifier','RUSBoostClassifier','Voting']):\n",
    "    scores = cross_val_score(clf, X_train_scaled, y_train, scoring='accuracy', cv=25)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
