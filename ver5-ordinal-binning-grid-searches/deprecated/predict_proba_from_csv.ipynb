{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict class membership from live data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read top 10 lines from csv\n",
    "\n",
    "\n",
    "surge or precursor?\n",
    "\n",
    "if precursor, compress to precursor\n",
    "\n",
    "predict precursor versus the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .pkl model, if not there, load it\n",
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab top ten lines from the newest csv\n",
    "\n",
    "#form into dataframe, caps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_df = capsFrame   \n",
    "lookback_period = 10 # in rows\n",
    "caps_df['change'] = caps_df['mp'].pct_change(periods=lookback_period)\n",
    "caps_df['bc_change'] = caps_df['bc'].pct_change(periods=lookback_period)\n",
    "caps_df['ac_change'] = caps_df['ac'].pct_change(periods=lookback_period)\n",
    "caps_df['tav_change'] = caps_df['tav'].pct_change(periods=lookback_period)\n",
    "caps_df['tbv_change'] = caps_df['tbv'].pct_change(periods=lookback_period)\n",
    "\n",
    "#for period, average or mean change metric. this changes with window size\n",
    "meanChange = round(caps_df['change'].mean(),8)\n",
    "meanChange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine precursor or surge\n",
    "# identify units of 10 rows where the percent change is greater or less than the threshold\n",
    "### key components: bc_change, ac_change, tav_change, tbv_change, change\n",
    "threshold = meanChange\n",
    "surges = []\n",
    "precursors = []\n",
    "for i in range(0,len(caps_df),10):\n",
    "    if caps_df.iloc[i:i+10]['change'].mean() >= threshold:\n",
    "        surges.append({'time': caps_df.iloc[i]['time'],\n",
    "                       's_MP': caps_df.iloc[i]['mp'],\n",
    "                       'change': caps_df.iloc[i:i+10]['change'].mean(),\n",
    "                       'type':'surge'})  #['bc', 'ac', 'tbv', 'tav', 'time', 'mp', 'minBid', 'change']\n",
    "    else:\n",
    "        precursors.append({'time': caps_df.iloc[i]['time'],\n",
    "                           'p_MP': caps_df.iloc[i]['mp'],\n",
    "                           'change': caps_df.iloc[i:i+10]['change'].mean(),\n",
    "                            'type':'precursor',\n",
    "                            'precursor_buy_cap_pct_change':caps_df.iloc[i]['bc_change'], \n",
    "                            'precursor_ask_cap_pct_change':caps_df.iloc[i]['ac_change'],\n",
    "                            'precursor_bid_vol_pct_change':caps_df.iloc[i]['tbv_change'],\n",
    "                            'precursor_ask_vol_pct_change':caps_df.iloc[i]['tav_change']\n",
    "                            })  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df['group'] = (sequence_df['type'] != sequence_df['type'].shift(1)).cumsum()\n",
    "columns_to_transform = [\n",
    "    'precursor_buy_cap_pct_change',\n",
    "    'precursor_ask_cap_pct_change',\n",
    "    'precursor_bid_vol_pct_change',\n",
    "    'precursor_ask_vol_pct_change'\n",
    "]\n",
    "\n",
    "for col in columns_to_transform:\n",
    "    sequence_df[col] = sequence_df.groupby('group')[col].transform(lambda x: x.sum() if not x.isna().all() else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # impute missing values with last non-null value DONE PRIOR, NOW AT START\n",
    "sequence_df['s_MP'] = sequence_df['s_MP'].fillna(method='ffill')\n",
    "sequence_df['p_MP'] = sequence_df['p_MP'].fillna(method='ffill')\n",
    "sequence_df['precursor_buy_cap_pct_change'] = sequence_df['precursor_buy_cap_pct_change'].fillna(method='ffill')\n",
    "sequence_df['precursor_ask_cap_pct_change'] = sequence_df['precursor_ask_cap_pct_change'].fillna(method='ffill')\n",
    "sequence_df['precursor_bid_vol_pct_change'] = sequence_df['precursor_bid_vol_pct_change'].fillna(method='ffill')\n",
    "sequence_df['precursor_ask_vol_pct_change'] = sequence_df['precursor_ask_vol_pct_change'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate surge lines from the following, and keep only precursor values\n",
    "sequence_df['length'] = sequence_df.groupby(['type', 'group'])['group'].transform('count')\n",
    "\n",
    "print(sequence_df.shape[0])\n",
    "sequence_df['sum_change'] = sequence_df.groupby(['type', 'group'])['change'].transform('sum')\n",
    "\n",
    "sequence_df['max_surge_mp'] = sequence_df.groupby(['type', 'group'])['s_MP'].transform('max')\n",
    "sequence_df['min_surge_mp'] = sequence_df.groupby(['type', 'group'])['s_MP'].transform('min')\n",
    "\n",
    "sequence_df['max_precursor_mp'] = sequence_df.groupby(['type', 'group'])['p_MP'].transform('max')\n",
    "sequence_df['min_precursor_mp'] = sequence_df.groupby(['type', 'group'])['p_MP'].transform('min')\n",
    "\n",
    "sequence_df['area']  = sequence_df.apply(lambda row: row['length'] * row['sum_change'], axis=1)\n",
    "\n",
    "sequence_df.loc[sequence_df['type'] == 'surge', 'surge_area'] = sequence_df.loc[sequence_df['type'] == 'surge', 'area']\n",
    "\n",
    "sequence_df['surge_targets_met_pct']  = sequence_df.apply(lambda group: ((group['max_precursor_mp']-group['max_surge_mp'])/group['max_surge_mp']  ) *100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the keepable values only to perform 'predict'\n",
    "\n",
    "keepable = ['precursor_buy_cap_pct_change', \n",
    "            'precursor_ask_cap_pct_change',\n",
    "            'precursor_bid_vol_pct_change', \n",
    "            'precursor_ask_vol_pct_change',\n",
    "            'sum_change',\n",
    "            'length',\n",
    "            'surge_targets_met_pct']\n",
    "x = m2_pipeline[['surge_targets_met_pct']].values.astype(float)\n",
    "m2_pipeline = m2_pipeline[keepable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize the rows to observe this format: \n",
    "m2_pipeline = m2_pipeline.dropna()\n",
    "\n",
    "# Splitting the dataframe into features and labels\n",
    "X = m2_pipeline[['precursor_buy_cap_pct_change', 'precursor_ask_cap_pct_change','precursor_bid_vol_pct_change',\n",
    "                'precursor_ask_vol_pct_change','sum_change', 'length']]\n",
    "y = m2_pipeline['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare pipeline versus model\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your input data\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Predict using the loaded classifier model\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
