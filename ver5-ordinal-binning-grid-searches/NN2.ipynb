{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from 642 tutorial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, linewidth=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = m2_pipeline\n",
    "y = m2_pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train = torch.as_tensor(y_train, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_v1, self).__init__() # initialize the parent class \n",
    "\n",
    "        self.fc1   = nn.Linear(in_features=8, out_features=16)  # in_features is the data dim, 8\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Linear(in_features=16, out_features=16) # In middle layers, in_features must match the last out_features\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3   = nn.Linear(in_features=16, out_features=1)  # out_features is the label dim, 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_v1 = NeuralNetwork_v1().to(device) # .to method can also move an entire model to device\n",
    "print(model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "inputs = inputs.to(device) # data must reside on the same device\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model_v1(inputs) # call your model as if it were a function\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inputs[:3] #3 data vectors of size 8\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_out = model_v1.fc1(x) # nn.Linear(in_features=8, out_features=16)\n",
    "print(fc1_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before ReLU: {fc1_out}\\n\\n\")\n",
    "relu1_out = model_v1.relu1(fc1_out) # nn.ReLU()\n",
    "print(f\"After ReLU: {relu1_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_v2, self).__init__() # initialize the parent class \n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=16),  # in_features is the data dim, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=16), # In middle layers, in_features must match the last out_features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=1),  # out_features is the label dim, 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x) # no need to pass x around anymore; modules are called sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2 = NeuralNetwork_v2().to(device)\n",
    "outputs = model_v2(inputs) # call your model as if it were a function\n",
    "outputs.size() # get outputs of the same size as that of model_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_v3, self).__init__() # initialize the parent class \n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=8, out_features=16)  # in_features is the data dim, 8\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=16) # In middle layers, in_features must match the last out_features\n",
    "        self.fc3 = nn.Linear(in_features=16, out_features=1)  # out_features is the label dim, 1\n",
    "\n",
    "        # homework: use nn.ModuleList to hold the three layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(torch.relu(x)) # ReLU now is no longer a \"layer\", but just a function\n",
    "        x = self.fc3(torch.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3 = NeuralNetwork_v3().to(device)\n",
    "outputs = model_v3(inputs) # call your model as if it were a function\n",
    "outputs.size() # get outputs of the same size as that of model_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.allclose(F.relu(fc1_out), torch.relu(fc1_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model structure: {model_v1}\\n\\n\")\n",
    "\n",
    "for name, param in model_v1.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict using an NN: https://stackoverflow.com/a/51058062\n",
    "\n",
    "resource examples via https://github.com/jcjohnson/pytorch-examples"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
