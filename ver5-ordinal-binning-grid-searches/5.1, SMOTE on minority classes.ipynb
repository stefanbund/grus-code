{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip3 install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using SMOTE to overcome class imbalance\n",
    "\n",
    "for most desireable classes, 10/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold  #OR Stratfied KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]  # Based on your code, you might need a ravel call here, but I would look into how you're generating your y\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]  # See comment on ravel and  y_train\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    model = ...  # Choose a model here\n",
    "    model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "    print(f'f-score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label bins as 'good' or 'bad' if they are 9+ or 9-, one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new binary classfiers (NB, LR and such), run new GridSearch to locate best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrate new classifiers into a voting classifier or on their own\n",
    "\n",
    "# look at feature breakout using SHAP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting on each method, error analysis using confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train sampling permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results_ for hyperparameter study"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
