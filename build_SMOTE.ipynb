{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand a labeled dataset to SMOTE\n",
    "\n",
    "magnify the number of minority/exceptional cases within the sequence dataset, ideally targets the binary binned dataset.\n",
    "\n",
    "[reference 1](<ver5-ordinal-binning-grid-searches/step 2-0, ranged clustering, with time.ipynb>)\n",
    "\n",
    "different oversampling tools: Naive random oversampling, SMOTE, ADASYN, SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from collections import Counter\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_pipeline = pd.read_csv(\"binary_binned_pipeline1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_pipeline.columns #do this to identify the index of the categorical feature, for below setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up toolsets as functions to build separate datasets, bin_Naive, bin_SMOTE, bin_ADASYN\n",
    "\n",
    "def build_naive(d):  #https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    print(\"ROS\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_smote(d): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#smote\n",
    "    X_resampled, y_resampled = SMOTE(random_state=42,categorical_features='label', categorical_encoder=None, ).fit_resample(X, y)\n",
    "    print(\"SMOTE\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_adasyn(d): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#adasyn\n",
    "    X_resampled, y_resampled = ADASYN(random_state=42).fit_resample(X, y)\n",
    "    print(\"ADASYN\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_borderline(d): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#borderlinesmote\n",
    "    X_resampled, y_resampled = BorderlineSMOTE(random_state=42).fit_resample(X, y)\n",
    "    print(\"BORDERLINE\",sorted(Counter(y_resampled).items())) \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_smotenc(d): #https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#smotenc\n",
    "    smote_nc = SMOTENC(categorical_features=[0, 2], random_state=42)\n",
    "    X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "    print(\"SMOTENC\",sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_svmsmote(d):\n",
    "    sm = SVMSMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    print(\"SVMSMOTE\",'Resampled dataset shape %s' % Counter(y_res))\n",
    "    return X_res, y_res\n",
    "\n",
    "def build_kmsmote(d):\n",
    "    m = KMeansSMOTE(kmeans_estimator=MiniBatchKMeans(n_init=1, random_state=0), random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    # Find the number of new samples in the middle blob\n",
    "    n_res_in_middle = ((X_res[:, 0] > -5) & (X_res[:, 0] < 5)).sum()\n",
    "    print(\"KMSMOTE\",\"Samples in the middle blob: %s\" % n_res_in_middle)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each oversampled dataset, then run the classifier search on that set, outlining each set, before hand\n",
    "\n",
    "#for each set, run the classifier search\n",
    "source = 'binary_binned_pipeline.csv'\n",
    "resultSet = []\n",
    "resultSet.append(getBestClassifier('naive', build_naive(source)))\n",
    "resultSet.append(getBestClassifier('smote', build_smote(source)))\n",
    "resultSet.append(getBestClassifier('adasyn', build_adasyn(source)))\n",
    "resultSet.append(getBestClassifier('borderline', build_borderline(source)))\n",
    "resultSet.append(getBestClassifier('smotenc', build_smotenc(source)))\n",
    "resultSet.append(getBestClassifier('svmsmote', build_svmsmote(source)))\n",
    "resultSet.append(getBestClassifier('kmsmote', build_svmsmote(source)))\n",
    "resultDF = pd.DataFrame(resultSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take optimal classifier parameters and technique"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
